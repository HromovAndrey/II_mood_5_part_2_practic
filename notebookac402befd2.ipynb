{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":1449674,"sourceType":"datasetVersion","datasetId":849724},{"sourceId":3866368,"sourceType":"datasetVersion","datasetId":849073}],"dockerImageVersionId":30746,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/andrey36912/notebookac402befd2?scriptVersionId=192771530\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"import numpy as np\nimport os\nfrom torchvision import datasets, transforms\nfrom torch.utils.data import DataLoader, random_split, ConcatDataset\nimport torch\nfrom torch import nn\nimport torch.nn.functional as F\nimport matplotlib.pyplot as plt\nfrom PIL import Image","metadata":{"execution":{"iopub.status.busy":"2024-08-14T19:35:27.235496Z","iopub.execute_input":"2024-08-14T19:35:27.235964Z","iopub.status.idle":"2024-08-14T19:35:27.243198Z","shell.execute_reply.started":"2024-08-14T19:35:27.235929Z","shell.execute_reply":"2024-08-14T19:35:27.241543Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","metadata":{"execution":{"iopub.status.busy":"2024-08-14T19:35:27.24548Z","iopub.execute_input":"2024-08-14T19:35:27.246Z","iopub.status.idle":"2024-08-14T19:35:27.257454Z","shell.execute_reply.started":"2024-08-14T19:35:27.245958Z","shell.execute_reply":"2024-08-14T19:35:27.256142Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"data_dir = '/kaggle/input/leukemia-classification/C-NMC_Leukemia/training_data/fold_0'\n\n\ndataset = datasets.ImageFolder(root=data_dir)","metadata":{"execution":{"iopub.status.busy":"2024-08-14T19:35:27.258868Z","iopub.execute_input":"2024-08-14T19:35:27.259253Z","iopub.status.idle":"2024-08-14T19:35:27.788455Z","shell.execute_reply.started":"2024-08-14T19:35:27.259221Z","shell.execute_reply":"2024-08-14T19:35:27.787183Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"data_dir = '/kaggle/input/leukemia-classification/C-NMC_Leukemia/training_data/fold_1'\ndataset1 = datasets.ImageFolder(root=data_dir)","metadata":{"execution":{"iopub.status.busy":"2024-08-14T19:35:27.791395Z","iopub.execute_input":"2024-08-14T19:35:27.791777Z","iopub.status.idle":"2024-08-14T19:35:28.304576Z","shell.execute_reply.started":"2024-08-14T19:35:27.791745Z","shell.execute_reply":"2024-08-14T19:35:28.30344Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"data_dir = '/kaggle/input/leukemia-classification/C-NMC_Leukemia/training_data/fold_2'\ndataset2 = datasets.ImageFolder(root=data_dir)","metadata":{"execution":{"iopub.status.busy":"2024-08-14T19:35:28.305912Z","iopub.execute_input":"2024-08-14T19:35:28.306259Z","iopub.status.idle":"2024-08-14T19:35:28.803902Z","shell.execute_reply.started":"2024-08-14T19:35:28.306229Z","shell.execute_reply":"2024-08-14T19:35:28.802694Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"classes = dataset_0.classes\nnum_classes = len(classes)","metadata":{"execution":{"iopub.status.busy":"2024-08-14T19:35:28.805122Z","iopub.execute_input":"2024-08-14T19:35:28.805505Z","iopub.status.idle":"2024-08-14T19:35:28.843087Z","shell.execute_reply.started":"2024-08-14T19:35:28.805473Z","shell.execute_reply":"2024-08-14T19:35:28.839876Z"},"trusted":true},"execution_count":15,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m classes \u001b[38;5;241m=\u001b[39m \u001b[43mdataset_0\u001b[49m\u001b[38;5;241m.\u001b[39mclasses\n\u001b[1;32m      2\u001b[0m num_classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(classes)\n","\u001b[0;31mNameError\u001b[0m: name 'dataset_0' is not defined"],"ename":"NameError","evalue":"name 'dataset_0' is not defined","output_type":"error"}]},{"cell_type":"code","source":"dataset = ConcatDataset([dataset_0, dataset_1, dataset_2])\nprint(f\"Количество классов: {num_classes}\")\nprint(f\"Классы: {classes}\")","metadata":{"execution":{"iopub.status.busy":"2024-08-14T19:35:28.844799Z","iopub.status.idle":"2024-08-14T19:35:28.845339Z","shell.execute_reply.started":"2024-08-14T19:35:28.845075Z","shell.execute_reply":"2024-08-14T19:35:28.845103Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = FractureClassifier(num_classes).to(device)\nprint(model)","metadata":{"execution":{"iopub.status.busy":"2024-08-14T19:35:28.847128Z","iopub.status.idle":"2024-08-14T19:35:28.847683Z","shell.execute_reply.started":"2024-08-14T19:35:28.847445Z","shell.execute_reply":"2024-08-14T19:35:28.847465Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_transform = transforms.Compose([\n    transforms.Resize((256, 256)),\n    transforms.RandomHorizontalFlip(p=0.5),\n    transforms.ToTensor(),\n])\n\ntest_transform = transforms.Compose([\n    transforms.Resize((256, 256)),\n    transforms.ToTensor(),\n])\n","metadata":{"execution":{"iopub.status.busy":"2024-08-14T19:35:28.849827Z","iopub.status.idle":"2024-08-14T19:35:28.850848Z","shell.execute_reply.started":"2024-08-14T19:35:28.850526Z","shell.execute_reply":"2024-08-14T19:35:28.850555Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(train_data), len(val_data)","metadata":{"execution":{"iopub.status.busy":"2024-08-14T19:35:28.852563Z","iopub.status.idle":"2024-08-14T19:35:28.852988Z","shell.execute_reply.started":"2024-08-14T19:35:28.85279Z","shell.execute_reply":"2024-08-14T19:35:28.852807Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_ratio = 0.8\ntrain_size = int(train_ratio * len(dataset))\nval_size = len(dataset) - train_size\ntrain_data, val_data = random_split(dataset, [train_size, val_size])\ntrain_data.dataset.transform = train_transform\nval_data.dataset.transform = test_transform","metadata":{"execution":{"iopub.status.busy":"2024-08-14T19:35:28.854528Z","iopub.status.idle":"2024-08-14T19:35:28.854954Z","shell.execute_reply.started":"2024-08-14T19:35:28.854758Z","shell.execute_reply":"2024-08-14T19:35:28.854775Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(train_data), len(val_data)","metadata":{"execution":{"iopub.status.busy":"2024-08-14T19:35:28.856331Z","iopub.status.idle":"2024-08-14T19:35:28.85678Z","shell.execute_reply.started":"2024-08-14T19:35:28.856577Z","shell.execute_reply":"2024-08-14T19:35:28.856594Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_size = 32\ntrain_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\nval_loader = DataLoader(val_data, shuffle=False, batch_size=batch_size)","metadata":{"execution":{"iopub.status.busy":"2024-08-14T19:35:28.857992Z","iopub.status.idle":"2024-08-14T19:35:28.858442Z","shell.execute_reply.started":"2024-08-14T19:35:28.8582Z","shell.execute_reply":"2024-08-14T19:35:28.858217Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ImageDataset(torch.utils.data.Dataset):\n   \n    def __init__(self, root_dir, transform=None):\n       \n        self.root_dir = root_dir\n        self.image_paths, self.labels = self.get_paths_and_labels()\n        self.transform = transform\n\n    def get_paths_and_labels(self):\n        image_paths = []\n        labels = []\n        for label in os.listdir(self.root_dir):\n            class_dir = os.path.join(self.root_dir, label)\n            if os.path.isdir(class_dir):\n                for img_name in os.listdir(class_dir):\n                    img_path = os.path.join(class_dir, img_name)\n                    image_paths.append(img_path)\n                    labels.append(label)\n        return image_paths, labels\n\n    def __len__(self):\n        return len(self.image_paths)\n\n    def __getitem__(self, idx):\n        image_path = self.image_paths[idx]\n        image = Image.open(image_path).convert('RGB')\n        label_name = self.labels[idx]\n        label = 0 if label_name == 'all' else 1  \n        if self.transform:\n            image = self.transform(image)\n        return image, label","metadata":{"execution":{"iopub.status.busy":"2024-08-14T19:35:28.860305Z","iopub.status.idle":"2024-08-14T19:35:28.860859Z","shell.execute_reply.started":"2024-08-14T19:35:28.86058Z","shell.execute_reply":"2024-08-14T19:35:28.86061Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"os.listdir(data_dir)","metadata":{"execution":{"iopub.status.busy":"2024-08-14T19:35:28.862786Z","iopub.status.idle":"2024-08-14T19:35:28.863168Z","shell.execute_reply.started":"2024-08-14T19:35:28.862982Z","shell.execute_reply":"2024-08-14T19:35:28.862997Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"custom_train_data = ImageDataset(data_dir, transform=transform)","metadata":{"execution":{"iopub.status.busy":"2024-08-14T19:35:28.864536Z","iopub.status.idle":"2024-08-14T19:35:28.864919Z","shell.execute_reply.started":"2024-08-14T19:35:28.864735Z","shell.execute_reply":"2024-08-14T19:35:28.86475Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nbatch_size = 32\ntrain_loader = DataLoader(custom_train_data, shuffle=True, batch_size=batch_size)","metadata":{"execution":{"iopub.status.busy":"2024-08-14T19:35:28.866064Z","iopub.status.idle":"2024-08-14T19:35:28.866517Z","shell.execute_reply.started":"2024-08-14T19:35:28.866276Z","shell.execute_reply":"2024-08-14T19:35:28.866292Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nfor i in range(3):  \n    img, label = custom_train_data[i]\n\n    img = img.numpy().transpose((1, 2, 0))  \n\n    plt.imshow(img)\n    plt.title(f\"Image: {i+1}, Label: {label}\")\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2024-08-14T19:35:28.867711Z","iopub.status.idle":"2024-08-14T19:35:28.868107Z","shell.execute_reply.started":"2024-08-14T19:35:28.867915Z","shell.execute_reply":"2024-08-14T19:35:28.867931Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class FractureClassifier(nn.Module):\n    def __init__(self, num_classes):\n        super().__init__()\n        self.conv1 = nn.Conv2d(in_channels=3, out_channels=8, kernel_size=3)\n        self.conv2 = nn.Conv2d(in_channels=8, out_channels=16, kernel_size=3)\n        self.conv3 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3)\n        self.conv4 = nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3)\n        self.conv5 = nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3)\n        self.conv6 = nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3)\n        \n        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n        self.pool4 = nn.MaxPool2d(kernel_size=2, stride=2)\n        self.pool5 = nn.MaxPool2d(kernel_size=2, stride=2)\n        \n        self.flatten = nn.Flatten()\n        \n        self.linear1 = nn.Linear(32*6*6, 256)\n        self.linear2 = nn.Linear(256, num_classes)\n        \n    def forward(self, x):\n        out = self.conv1(x)\n        out = F.relu(out)\n        out = self.conv2(out)\n        out = F.relu(out)\n        out = self.pool1(out)\n        out = self.conv3(out)\n        out = F.relu(out)\n        out = self.pool2(out)\n        out = self.conv4(out)\n        out = F.relu(out)\n        out = self.pool3(out)\n        out = self.conv5(out)\n        out = F.relu(out)\n        out = self.pool4(out)\n        out = self.conv6(out)\n        out = F.relu(out)\n        out = self.pool5(out)\n        out = self.flatten(out)\n        out = self.linear1(out)\n        out = F.relu(out)\n        out = self.linear2(out)\n        return out\n    \n    def predict(self, X, device='cpu'):\n        X = torch.FloatTensor(np.array(X)).to(device)\n        with torch.no_grad():\n            y_pred = self.forward(X)\n        return y_pred.cpu().numpy()\nmodel = FractureClassifier(num_classes).to(device)\nprint(model)\n    ","metadata":{"execution":{"iopub.status.busy":"2024-08-14T19:35:28.869578Z","iopub.status.idle":"2024-08-14T19:35:28.869975Z","shell.execute_reply.started":"2024-08-14T19:35:28.869788Z","shell.execute_reply":"2024-08-14T19:35:28.869804Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install -q torchsummary","metadata":{"execution":{"iopub.status.busy":"2024-08-14T19:35:28.871805Z","iopub.status.idle":"2024-08-14T19:35:28.87238Z","shell.execute_reply.started":"2024-08-14T19:35:28.87208Z","shell.execute_reply":"2024-08-14T19:35:28.872101Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torchsummary import summary\n\nsummary(model, input_size=(3, 256, 256))","metadata":{"execution":{"iopub.status.busy":"2024-08-14T19:35:28.873797Z","iopub.status.idle":"2024-08-14T19:35:28.874231Z","shell.execute_reply.started":"2024-08-14T19:35:28.874025Z","shell.execute_reply":"2024-08-14T19:35:28.874047Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss_fn = nn.CrossEntropyLoss()\n\noptimizer = torch.optim.Adam(model.parameters(), lr=0.001)","metadata":{"execution":{"iopub.status.busy":"2024-08-14T19:35:28.876371Z","iopub.status.idle":"2024-08-14T19:35:28.876777Z","shell.execute_reply.started":"2024-08-14T19:35:28.876581Z","shell.execute_reply":"2024-08-14T19:35:28.876597Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, roc_auc_score\n\nhistory = train(model, optimizer, loss_fn, train_loader, val_loader,\n                epochs=10,\n                metrics=[accuracy_score],\n                device=device,\n                task='multiclass')","metadata":{"execution":{"iopub.status.busy":"2024-08-14T19:35:28.878125Z","iopub.status.idle":"2024-08-14T19:35:28.878602Z","shell.execute_reply.started":"2024-08-14T19:35:28.87838Z","shell.execute_reply":"2024-08-14T19:35:28.878409Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\ndef plot_metric(history, name):\n    plt.title(f\"Model results with {name}\")\n    plt.plot(history[name], label='train')\n    plt.plot(history['val_'+name], label='val')\n    plt.xlabel('Epoch')\n    plt.ylabel(name)\n    plt.legend()\n\n\nplot_metric(history, 'loss')","metadata":{"execution":{"iopub.status.busy":"2024-08-14T19:35:28.879922Z","iopub.status.idle":"2024-08-14T19:35:28.8803Z","shell.execute_reply.started":"2024-08-14T19:35:28.880115Z","shell.execute_reply":"2024-08-14T19:35:28.88013Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport os\nfrom torchvision import datasets, transforms\nfrom torch.utils.data import DataLoader, random_split, ConcatDataset\nimport torch\nfrom torch import nn\nimport torch.nn.functional as F\nimport matplotlib.pyplot as plt\nfrom PIL import Image\n\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\n# Определение путей к данным\ndata_dir_0 = '/kaggle/input/leukemia-classification/C-NMC_Leukemia/training_data/fold_0'\ndata_dir_1 = '/kaggle/input/leukemia-classification/C-NMC_Leukemia/training_data/fold_1'\ndata_dir_2 = '/kaggle/input/leukemia-classification/C-NMC_Leukemia/training_data/fold_2'\n\n# Применение трансформаций\ntransform = transforms.Compose([\n    transforms.Resize((256, 256)),\n    transforms.RandomHorizontalFlip(p=0.5),\n    transforms.ToTensor(),\n])\n\n# Загрузка данных с применением трансформаций\ndataset_0 = datasets.ImageFolder(root=data_dir_0, transform=transform)\ndataset_1 = datasets.ImageFolder(root=data_dir_1, transform=transform)\ndataset_2 = datasets.ImageFolder(root=data_dir_2, transform=transform)\n\n# Извлечение классов\nclasses = dataset_0.classes\nnum_classes = len(classes)\n\n# Объединение датасетов\ndataset = ConcatDataset([dataset_0, dataset_1, dataset_2])\n\n# Разделение данных на обучающую и валидационную выборки\ntrain_ratio = 0.8\ntrain_size = int(train_ratio * len(dataset))\nval_size = len(dataset) - train_size\ntrain_data, val_data = random_split(dataset, [train_size, val_size])\n\n# Загрузчики данных\nbatch_size = 32\ntrain_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\nval_loader = DataLoader(val_data, shuffle=False, batch_size=batch_size)\n\n# Определение модели\nclass FractureClassifier(nn.Module):\n    def __init__(self, num_classes):\n        super().__init__()\n        self.conv1 = nn.Conv2d(in_channels=3, out_channels=8, kernel_size=3)\n        self.conv2 = nn.Conv2d(in_channels=8, out_channels=16, kernel_size=3)\n        self.conv3 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3)\n        self.conv4 = nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3)\n        self.conv5 = nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3)\n        self.conv6 = nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3)\n        \n        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n        self.pool4 = nn.MaxPool2d(kernel_size=2, stride=2)\n        self.pool5 = nn.MaxPool2d(kernel_size=2, stride=2)\n        \n        self.flatten = nn.Flatten()\n        \n        self.linear1 = nn.Linear(32*6*6, 256)\n        self.linear2 = nn.Linear(256, num_classes)\n        \n    def forward(self, x):\n        out = self.conv1(x)\n        out = F.relu(out)\n        out = self.conv2(out)\n        out = F.relu(out)\n        out = self.pool1(out)\n        out = self.conv3(out)\n        out = F.relu(out)\n        out = self.pool2(out)\n        out = self.conv4(out)\n        out = F.relu(out)\n        out = self.pool3(out)\n        out = self.conv5(out)\n        out = F.relu(out)\n        out = self.pool4(out)\n        out = self.conv6(out)\n        out = F.relu(out)\n        out = self.pool5(out)\n        out = self.flatten(out)\n        out = self.linear1(out)\n        out = F.relu(out)\n        out = self.linear2(out)\n        return out\n    \n    def predict(self, X, device='cpu'):\n        X = torch.FloatTensor(np.array(X)).to(device)\n        with torch.no_grad():\n            y_pred = self.forward(X)\n        return y_pred.cpu().numpy()\n\nmodel = FractureClassifier(num_classes).to(device)\nprint(model)\n\n# Обучение модели\nloss_fn = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n\n# Обучение\nfrom sklearn.metrics import accuracy_score\n\nhistory = train(model, optimizer, loss_fn, train_loader, val_loader,\n                epochs=10,\n                metrics=[accuracy_score],\n                device=device,\n                task='multiclass')\n","metadata":{"execution":{"iopub.status.busy":"2024-08-14T19:35:28.882315Z","iopub.status.idle":"2024-08-14T19:35:28.882941Z","shell.execute_reply.started":"2024-08-14T19:35:28.882619Z","shell.execute_reply":"2024-08-14T19:35:28.882642Z"},"trusted":true},"execution_count":null,"outputs":[]}]}