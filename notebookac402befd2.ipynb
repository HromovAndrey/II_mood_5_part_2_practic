{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":1449674,"sourceType":"datasetVersion","datasetId":849724},{"sourceId":3866368,"sourceType":"datasetVersion","datasetId":849073}],"dockerImageVersionId":30746,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/andrey36912/notebookac402befd2?scriptVersionId=192773734\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"import numpy as np\nimport os\nfrom torchvision import datasets, transforms\nfrom torch.utils.data import DataLoader, random_split, ConcatDataset\nimport torch\nfrom torch import nn\nimport torch.nn.functional as F\nimport matplotlib.pyplot as plt\nfrom PIL import Image","metadata":{"execution":{"iopub.status.busy":"2024-08-15T15:18:36.740425Z","iopub.execute_input":"2024-08-15T15:18:36.741183Z","iopub.status.idle":"2024-08-15T15:18:36.747822Z","shell.execute_reply.started":"2024-08-15T15:18:36.74114Z","shell.execute_reply":"2024-08-15T15:18:36.74637Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","metadata":{"execution":{"iopub.status.busy":"2024-08-15T15:18:36.75019Z","iopub.execute_input":"2024-08-15T15:18:36.750676Z","iopub.status.idle":"2024-08-15T15:18:36.759476Z","shell.execute_reply.started":"2024-08-15T15:18:36.750635Z","shell.execute_reply":"2024-08-15T15:18:36.758196Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"data_dir = '/kaggle/input/leukemia-classification/C-NMC_Leukemia/training_data/fold_0'\n\n\ndataset = datasets.ImageFolder(root=data_dir)","metadata":{"execution":{"iopub.status.busy":"2024-08-15T15:18:36.761573Z","iopub.execute_input":"2024-08-15T15:18:36.762448Z","iopub.status.idle":"2024-08-15T15:18:37.312252Z","shell.execute_reply.started":"2024-08-15T15:18:36.762408Z","shell.execute_reply":"2024-08-15T15:18:37.310914Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"data_dir = '/kaggle/input/leukemia-classification/C-NMC_Leukemia/training_data/fold_1'\ndataset1 = datasets.ImageFolder(root=data_dir)","metadata":{"execution":{"iopub.status.busy":"2024-08-15T15:18:37.316518Z","iopub.execute_input":"2024-08-15T15:18:37.317508Z","iopub.status.idle":"2024-08-15T15:18:37.878403Z","shell.execute_reply.started":"2024-08-15T15:18:37.317472Z","shell.execute_reply":"2024-08-15T15:18:37.877214Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"data_dir = '/kaggle/input/leukemia-classification/C-NMC_Leukemia/training_data/fold_2'\ndataset2 = datasets.ImageFolder(root=data_dir)","metadata":{"execution":{"iopub.status.busy":"2024-08-15T15:18:37.880087Z","iopub.execute_input":"2024-08-15T15:18:37.880689Z","iopub.status.idle":"2024-08-15T15:18:38.39871Z","shell.execute_reply.started":"2024-08-15T15:18:37.880655Z","shell.execute_reply":"2024-08-15T15:18:38.397649Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import ConcatDataset\ndataset = ConcatDataset([dataset, dataset1, dataset2])\nlen(dataset)","metadata":{"execution":{"iopub.status.busy":"2024-08-15T15:26:31.737326Z","iopub.execute_input":"2024-08-15T15:26:31.737747Z","iopub.status.idle":"2024-08-15T15:26:31.747455Z","shell.execute_reply.started":"2024-08-15T15:26:31.737715Z","shell.execute_reply":"2024-08-15T15:26:31.746255Z"},"trusted":true},"execution_count":27,"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"10661"},"metadata":{}}]},{"cell_type":"code","source":"dataset.classes\n","metadata":{"execution":{"iopub.status.busy":"2024-08-15T15:26:48.417352Z","iopub.execute_input":"2024-08-15T15:26:48.41778Z","iopub.status.idle":"2024-08-15T15:26:48.451256Z","shell.execute_reply.started":"2024-08-15T15:26:48.417749Z","shell.execute_reply":"2024-08-15T15:26:48.449706Z"},"trusted":true},"execution_count":28,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","Cell \u001b[0;32mIn[28], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclasses\u001b[49m\n","\u001b[0;31mAttributeError\u001b[0m: 'ConcatDataset' object has no attribute 'classes'"],"ename":"AttributeError","evalue":"'ConcatDataset' object has no attribute 'classes'","output_type":"error"}]},{"cell_type":"code","source":"train_transform = transforms.Compose([\n    transforms.Resize((256, 256)),\n    transforms.RandomHorizontalFlip(p=0.5),\n    transforms.ToTensor(),\n])\n\ntest_transform = transforms.Compose([\n    transforms.Resize((256, 256)),\n    transforms.ToTensor(),\n])\n","metadata":{"execution":{"iopub.status.busy":"2024-08-15T15:18:38.408837Z","iopub.execute_input":"2024-08-15T15:18:38.409272Z","iopub.status.idle":"2024-08-15T15:18:38.421285Z","shell.execute_reply.started":"2024-08-15T15:18:38.409231Z","shell.execute_reply":"2024-08-15T15:18:38.420074Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"len(train_data), len(val_data)","metadata":{"execution":{"iopub.status.busy":"2024-08-15T15:18:38.422679Z","iopub.execute_input":"2024-08-15T15:18:38.423125Z","iopub.status.idle":"2024-08-15T15:18:38.458622Z","shell.execute_reply.started":"2024-08-15T15:18:38.423077Z","shell.execute_reply":"2024-08-15T15:18:38.456193Z"},"trusted":true},"execution_count":24,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[24], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mlen\u001b[39m(\u001b[43mtrain_data\u001b[49m), \u001b[38;5;28mlen\u001b[39m(val_data)\n","\u001b[0;31mNameError\u001b[0m: name 'train_data' is not defined"],"ename":"NameError","evalue":"name 'train_data' is not defined","output_type":"error"}]},{"cell_type":"code","source":"train_ratio = 0.8\ntrain_size = int(train_ratio * len(dataset))\nval_size = len(dataset) - train_size\ntrain_data, val_data = random_split(dataset, [train_size, val_size])\ntrain_data.dataset.transform = train_transform\nval_data.dataset.transform = test_transform","metadata":{"execution":{"iopub.status.busy":"2024-08-15T15:18:38.460077Z","iopub.status.idle":"2024-08-15T15:18:38.460478Z","shell.execute_reply.started":"2024-08-15T15:18:38.460297Z","shell.execute_reply":"2024-08-15T15:18:38.460314Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(train_data), len(val_data)","metadata":{"execution":{"iopub.status.busy":"2024-08-15T15:18:38.462059Z","iopub.status.idle":"2024-08-15T15:18:38.462501Z","shell.execute_reply.started":"2024-08-15T15:18:38.462306Z","shell.execute_reply":"2024-08-15T15:18:38.462324Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_size = 32\ntrain_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\nval_loader = DataLoader(val_data, shuffle=False, batch_size=batch_size)","metadata":{"execution":{"iopub.status.busy":"2024-08-15T15:18:38.464416Z","iopub.status.idle":"2024-08-15T15:18:38.46485Z","shell.execute_reply.started":"2024-08-15T15:18:38.464638Z","shell.execute_reply":"2024-08-15T15:18:38.464656Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ImageDataset(torch.utils.data.Dataset):\n   \n    def __init__(self, root_dir, transform=None):\n       \n        self.root_dir = root_dir\n        self.image_paths, self.labels = self.get_paths_and_labels()\n        self.transform = transform\n\n    def get_paths_and_labels(self):\n        image_paths = []\n        labels = []\n        for label in os.listdir(self.root_dir):\n            class_dir = os.path.join(self.root_dir, label)\n            if os.path.isdir(class_dir):\n                for img_name in os.listdir(class_dir):\n                    img_path = os.path.join(class_dir, img_name)\n                    image_paths.append(img_path)\n                    labels.append(label)\n        return image_paths, labels\n\n    def __len__(self):\n        return len(self.image_paths)\n\n    def __getitem__(self, idx):\n        image_path = self.image_paths[idx]\n        image = Image.open(image_path).convert('RGB')\n        label_name = self.labels[idx]\n        label = 0 if label_name == 'all' else 1  \n        if self.transform:\n            image = self.transform(image)\n        return image, label","metadata":{"execution":{"iopub.status.busy":"2024-08-15T15:18:38.466155Z","iopub.status.idle":"2024-08-15T15:18:38.46655Z","shell.execute_reply.started":"2024-08-15T15:18:38.466362Z","shell.execute_reply":"2024-08-15T15:18:38.466381Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"os.listdir(data_dir)","metadata":{"execution":{"iopub.status.busy":"2024-08-15T15:18:38.46776Z","iopub.status.idle":"2024-08-15T15:18:38.468186Z","shell.execute_reply.started":"2024-08-15T15:18:38.46798Z","shell.execute_reply":"2024-08-15T15:18:38.467997Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"custom_train_data = ImageDataset(data_dir, transform=transform)","metadata":{"execution":{"iopub.status.busy":"2024-08-15T15:18:38.470813Z","iopub.status.idle":"2024-08-15T15:18:38.471392Z","shell.execute_reply.started":"2024-08-15T15:18:38.471116Z","shell.execute_reply":"2024-08-15T15:18:38.471143Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nbatch_size = 32\ntrain_loader = DataLoader(custom_train_data, shuffle=True, batch_size=batch_size)","metadata":{"execution":{"iopub.status.busy":"2024-08-15T15:18:38.473194Z","iopub.status.idle":"2024-08-15T15:18:38.473592Z","shell.execute_reply.started":"2024-08-15T15:18:38.473404Z","shell.execute_reply":"2024-08-15T15:18:38.473422Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nfor i in range(3):  \n    img, label = custom_train_data[i]\n\n    img = img.numpy().transpose((1, 2, 0))  \n\n    plt.imshow(img)\n    plt.title(f\"Image: {i+1}, Label: {label}\")\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2024-08-15T15:18:38.475233Z","iopub.status.idle":"2024-08-15T15:18:38.475653Z","shell.execute_reply.started":"2024-08-15T15:18:38.475439Z","shell.execute_reply":"2024-08-15T15:18:38.475457Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class FractureClassifier(nn.Module):\n    def __init__(self, num_classes):\n        super().__init__()\n        self.conv1 = nn.Conv2d(in_channels=3, out_channels=8, kernel_size=3)\n        self.conv2 = nn.Conv2d(in_channels=8, out_channels=16, kernel_size=3)\n        self.conv3 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3)\n        self.conv4 = nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3)\n        self.conv5 = nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3)\n        self.conv6 = nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3)\n        \n        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n        self.pool4 = nn.MaxPool2d(kernel_size=2, stride=2)\n        self.pool5 = nn.MaxPool2d(kernel_size=2, stride=2)\n        \n        self.flatten = nn.Flatten()\n        \n        self.linear1 = nn.Linear(32*6*6, 256)\n        self.linear2 = nn.Linear(256, num_classes)\n        \n    def forward(self, x):\n        out = self.conv1(x)\n        out = F.relu(out)\n        out = self.conv2(out)\n        out = F.relu(out)\n        out = self.pool1(out)\n        out = self.conv3(out)\n        out = F.relu(out)\n        out = self.pool2(out)\n        out = self.conv4(out)\n        out = F.relu(out)\n        out = self.pool3(out)\n        out = self.conv5(out)\n        out = F.relu(out)\n        out = self.pool4(out)\n        out = self.conv6(out)\n        out = F.relu(out)\n        out = self.pool5(out)\n        out = self.flatten(out)\n        out = self.linear1(out)\n        out = F.relu(out)\n        out = self.linear2(out)\n        return out\n    \n    def predict(self, X, device='cpu'):\n        X = torch.FloatTensor(np.array(X)).to(device)\n        with torch.no_grad():\n            y_pred = self.forward(X)\n        return y_pred.cpu().numpy()\nmodel = FractureClassifier(num_classes).to(device)\nprint(model)\n    ","metadata":{"execution":{"iopub.status.busy":"2024-08-15T15:18:38.47668Z","iopub.status.idle":"2024-08-15T15:18:38.477693Z","shell.execute_reply.started":"2024-08-15T15:18:38.477461Z","shell.execute_reply":"2024-08-15T15:18:38.477483Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install -q torchsummary","metadata":{"execution":{"iopub.status.busy":"2024-08-15T15:18:38.478743Z","iopub.status.idle":"2024-08-15T15:18:38.47917Z","shell.execute_reply.started":"2024-08-15T15:18:38.47899Z","shell.execute_reply":"2024-08-15T15:18:38.479008Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torchsummary import summary\n\nsummary(model, input_size=(3, 256, 256))","metadata":{"execution":{"iopub.status.busy":"2024-08-15T15:18:38.481295Z","iopub.status.idle":"2024-08-15T15:18:38.481841Z","shell.execute_reply.started":"2024-08-15T15:18:38.481562Z","shell.execute_reply":"2024-08-15T15:18:38.481585Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss_fn = nn.CrossEntropyLoss()\n\noptimizer = torch.optim.Adam(model.parameters(), lr=0.001)","metadata":{"execution":{"iopub.status.busy":"2024-08-15T15:18:38.483398Z","iopub.status.idle":"2024-08-15T15:18:38.483937Z","shell.execute_reply.started":"2024-08-15T15:18:38.483658Z","shell.execute_reply":"2024-08-15T15:18:38.483681Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, roc_auc_score\n\nhistory = train(model, optimizer, loss_fn, train_loader, val_loader,\n                epochs=10,\n                metrics=[accuracy_score],\n                device=device,\n                task='multiclass')","metadata":{"execution":{"iopub.status.busy":"2024-08-15T15:18:38.485881Z","iopub.status.idle":"2024-08-15T15:18:38.486391Z","shell.execute_reply.started":"2024-08-15T15:18:38.486133Z","shell.execute_reply":"2024-08-15T15:18:38.486155Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\ndef plot_metric(history, name):\n    plt.title(f\"Model results with {name}\")\n    plt.plot(history[name], label='train')\n    plt.plot(history['val_'+name], label='val')\n    plt.xlabel('Epoch')\n    plt.ylabel(name)\n    plt.legend()\n\n\nplot_metric(history, 'loss')","metadata":{"execution":{"iopub.status.busy":"2024-08-15T15:18:38.48837Z","iopub.status.idle":"2024-08-15T15:18:38.488834Z","shell.execute_reply.started":"2024-08-15T15:18:38.488607Z","shell.execute_reply":"2024-08-15T15:18:38.488631Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport os\nfrom torchvision import datasets, transforms\nfrom torch.utils.data import DataLoader, random_split, ConcatDataset\nimport torch\nfrom torch import nn\nimport torch.nn.functional as F\nimport matplotlib.pyplot as plt\nfrom PIL import Image\n\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\n# Определение путей к данным\ndata_dir_0 = '/kaggle/input/leukemia-classification/C-NMC_Leukemia/training_data/fold_0'\ndata_dir_1 = '/kaggle/input/leukemia-classification/C-NMC_Leukemia/training_data/fold_1'\ndata_dir_2 = '/kaggle/input/leukemia-classification/C-NMC_Leukemia/training_data/fold_2'\n\n# Применение трансформаций\ntransform = transforms.Compose([\n    transforms.Resize((256, 256)),\n    transforms.RandomHorizontalFlip(p=0.5),\n    transforms.ToTensor(),\n])\n\n# Загрузка данных с применением трансформаций\ndataset_0 = datasets.ImageFolder(root=data_dir_0, transform=transform)\ndataset_1 = datasets.ImageFolder(root=data_dir_1, transform=transform)\ndataset_2 = datasets.ImageFolder(root=data_dir_2, transform=transform)\n\n# Извлечение классов\nclasses = dataset_0.classes\nnum_classes = len(classes)\n\n# Объединение датасетов\ndataset = ConcatDataset([dataset_0, dataset_1, dataset_2])\n\n# Разделение данных на обучающую и валидационную выборки\ntrain_ratio = 0.8\ntrain_size = int(train_ratio * len(dataset))\nval_size = len(dataset) - train_size\ntrain_data, val_data = random_split(dataset, [train_size, val_size])\n\n# Загрузчики данных\nbatch_size = 32\ntrain_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\nval_loader = DataLoader(val_data, shuffle=False, batch_size=batch_size)\n\n# Определение модели\nclass FractureClassifier(nn.Module):\n    def __init__(self, num_classes):\n        super().__init__()\n        self.conv1 = nn.Conv2d(in_channels=3, out_channels=8, kernel_size=3)\n        self.conv2 = nn.Conv2d(in_channels=8, out_channels=16, kernel_size=3)\n        self.conv3 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3)\n        self.conv4 = nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3)\n        self.conv5 = nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3)\n        self.conv6 = nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3)\n        \n        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n        self.pool4 = nn.MaxPool2d(kernel_size=2, stride=2)\n        self.pool5 = nn.MaxPool2d(kernel_size=2, stride=2)\n        \n        self.flatten = nn.Flatten()\n        \n        self.linear1 = nn.Linear(32*6*6, 256)\n        self.linear2 = nn.Linear(256, num_classes)\n        \n    def forward(self, x):\n        out = self.conv1(x)\n        out = F.relu(out)\n        out = self.conv2(out)\n        out = F.relu(out)\n        out = self.pool1(out)\n        out = self.conv3(out)\n        out = F.relu(out)\n        out = self.pool2(out)\n        out = self.conv4(out)\n        out = F.relu(out)\n        out = self.pool3(out)\n        out = self.conv5(out)\n        out = F.relu(out)\n        out = self.pool4(out)\n        out = self.conv6(out)\n        out = F.relu(out)\n        out = self.pool5(out)\n        out = self.flatten(out)\n        out = self.linear1(out)\n        out = F.relu(out)\n        out = self.linear2(out)\n        return out\n    \n    def predict(self, X, device='cpu'):\n        X = torch.FloatTensor(np.array(X)).to(device)\n        with torch.no_grad():\n            y_pred = self.forward(X)\n        return y_pred.cpu().numpy()\n\nmodel = FractureClassifier(num_classes).to(device)\nprint(model)\n\n# Обучение модели\nloss_fn = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n\n# Обучение\nfrom sklearn.metrics import accuracy_score\n\nhistory = train(model, optimizer, loss_fn, train_loader, val_loader,\n                epochs=10,\n                metrics=[accuracy_score],\n                device=device,\n                task='multiclass')\n","metadata":{"execution":{"iopub.status.busy":"2024-08-15T15:18:38.490603Z","iopub.status.idle":"2024-08-15T15:18:38.491041Z","shell.execute_reply.started":"2024-08-15T15:18:38.490836Z","shell.execute_reply":"2024-08-15T15:18:38.490856Z"},"trusted":true},"execution_count":null,"outputs":[]}]}