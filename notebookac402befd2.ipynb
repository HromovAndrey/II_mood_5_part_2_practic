{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":1449674,"sourceType":"datasetVersion","datasetId":849724},{"sourceId":3866368,"sourceType":"datasetVersion","datasetId":849073}],"dockerImageVersionId":30746,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/andrey36912/notebookac402befd2?scriptVersionId=192666291\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nfrom torchvision import datasets, transforms\nfrom torch.utils.data import DataLoader, random_split\nimport torch\nfrom torchvision import datasets, transforms\nfrom PIL import Image\nfrom torch.utils.data import Dataset","metadata":{"execution":{"iopub.status.busy":"2024-08-14T16:45:07.853631Z","iopub.execute_input":"2024-08-14T16:45:07.854329Z","iopub.status.idle":"2024-08-14T16:45:07.862237Z","shell.execute_reply.started":"2024-08-14T16:45:07.854284Z","shell.execute_reply":"2024-08-14T16:45:07.860576Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","metadata":{"execution":{"iopub.status.busy":"2024-08-14T16:45:07.865477Z","iopub.execute_input":"2024-08-14T16:45:07.866465Z","iopub.status.idle":"2024-08-14T16:45:07.876811Z","shell.execute_reply.started":"2024-08-14T16:45:07.866372Z","shell.execute_reply":"2024-08-14T16:45:07.87506Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"data_dir = '/kaggle/input/leukemia-classification/C-NMC_Leukemia/training_data/fold_0'\n\n\ndataset = datasets.ImageFolder(root=data_dir)","metadata":{"execution":{"iopub.status.busy":"2024-08-14T16:45:07.878742Z","iopub.execute_input":"2024-08-14T16:45:07.879351Z","iopub.status.idle":"2024-08-14T16:45:09.82615Z","shell.execute_reply.started":"2024-08-14T16:45:07.879298Z","shell.execute_reply":"2024-08-14T16:45:09.824686Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"data_dir = '/kaggle/input/leukemia-classification/C-NMC_Leukemia/training_data/fold_1'\ndataset1 = datasets.ImageFolder(root=data_dir)","metadata":{"execution":{"iopub.status.busy":"2024-08-14T16:45:09.829821Z","iopub.execute_input":"2024-08-14T16:45:09.831293Z","iopub.status.idle":"2024-08-14T16:45:10.979503Z","shell.execute_reply.started":"2024-08-14T16:45:09.83122Z","shell.execute_reply":"2024-08-14T16:45:10.977863Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"data_dir = '/kaggle/input/leukemia-classification/C-NMC_Leukemia/training_data/fold_2'\ndataset2 = datasets.ImageFolder(root=data_dir)","metadata":{"execution":{"iopub.status.busy":"2024-08-14T16:45:10.982017Z","iopub.execute_input":"2024-08-14T16:45:10.982978Z","iopub.status.idle":"2024-08-14T16:45:12.446772Z","shell.execute_reply.started":"2024-08-14T16:45:10.982911Z","shell.execute_reply":"2024-08-14T16:45:12.445384Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import ConcatDataset\ndataset = ConcatDataset([dataset, dataset1, dataset2])\nlen(dataset)","metadata":{"execution":{"iopub.status.busy":"2024-08-14T16:45:12.448391Z","iopub.execute_input":"2024-08-14T16:45:12.448851Z","iopub.status.idle":"2024-08-14T16:45:12.458893Z","shell.execute_reply.started":"2024-08-14T16:45:12.448811Z","shell.execute_reply":"2024-08-14T16:45:12.457056Z"},"trusted":true},"execution_count":34,"outputs":[{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"10661"},"metadata":{}}]},{"cell_type":"code","source":"dataset.classes","metadata":{"execution":{"iopub.status.busy":"2024-08-14T16:45:12.460885Z","iopub.execute_input":"2024-08-14T16:45:12.461526Z","iopub.status.idle":"2024-08-14T16:45:12.514427Z","shell.execute_reply.started":"2024-08-14T16:45:12.461467Z","shell.execute_reply":"2024-08-14T16:45:12.510407Z"},"trusted":true},"execution_count":35,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","Cell \u001b[0;32mIn[35], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclasses\u001b[49m\n","\u001b[0;31mAttributeError\u001b[0m: 'ConcatDataset' object has no attribute 'classes'"],"ename":"AttributeError","evalue":"'ConcatDataset' object has no attribute 'classes'","output_type":"error"}]},{"cell_type":"code","source":"train_ratio = 0.8\ntrain_size = int(train_ratio * len(dataset))\nval_size = len(dataset) - train_size\n\ntrain_data, val_data = random_split(dataset, [train_size, val_size])","metadata":{"execution":{"iopub.status.busy":"2024-08-14T16:45:12.515793Z","iopub.status.idle":"2024-08-14T16:45:12.516335Z","shell.execute_reply.started":"2024-08-14T16:45:12.516103Z","shell.execute_reply":"2024-08-14T16:45:12.516124Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_transform = transforms.Compose([\n    transforms.Resize((256, 256)),\n    transforms.RandomHorizontalFlip(),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.5], std=[0.5])\n])\n\n# Трансформації для тестових даних\ntest_transform = transforms.Compose([\n    transforms.Resize((256, 256)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.5], std=[0.5])\n])","metadata":{"execution":{"iopub.status.busy":"2024-08-14T16:45:12.51893Z","iopub.status.idle":"2024-08-14T16:45:12.519535Z","shell.execute_reply.started":"2024-08-14T16:45:12.519258Z","shell.execute_reply":"2024-08-14T16:45:12.519281Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"custom_train_data = ImageDataset(data_dir, transform=train_transform)\ncustom_test_data = ImageDataset(data_dir, transform=test_transform)","metadata":{"execution":{"iopub.status.busy":"2024-08-14T16:45:12.521793Z","iopub.status.idle":"2024-08-14T16:45:12.522338Z","shell.execute_reply.started":"2024-08-14T16:45:12.522106Z","shell.execute_reply":"2024-08-14T16:45:12.522129Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nprint(f'Number of training samples: {len(custom_train_data)}')\nprint(f'Number of testing samples: {len(custom_test_data)}')","metadata":{"execution":{"iopub.status.busy":"2024-08-14T16:45:12.524322Z","iopub.status.idle":"2024-08-14T16:45:12.524907Z","shell.execute_reply.started":"2024-08-14T16:45:12.524656Z","shell.execute_reply":"2024-08-14T16:45:12.524678Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# Преобразуем Subset обратно в Dataset для визуализации\ntrain_dataset = train_data.dataset\nval_dataset = val_data.dataset\n\nfor i in range(3):\n    # Получаем изображение и метку из train_dataset\n    img, label = train_dataset[i]\n    \n    # Преобразуем изображение из Tensor в Numpy для отображения\n    img = img.numpy()\n    \n    # Переставляем оси для корректного отображения (от (C, H, W) к (H, W, C))\n    img = img.transpose((1, 2, 0))\n    \n    # Определяем метку\n    label_name = 'all' if label == 0 else 'hem'\n    \n    # Визуализация изображения\n    plt.imshow(img)\n    plt.title(f\"Image: {i+1}, Label: {label_name}\")\n    plt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-08-14T16:45:12.527228Z","iopub.status.idle":"2024-08-14T16:45:12.528313Z","shell.execute_reply.started":"2024-08-14T16:45:12.528046Z","shell.execute_reply":"2024-08-14T16:45:12.528073Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nfor i in range(3):  \n    img, label = custom_train_data[i]\n\n\n    img = img.numpy()\n\n   \n    img = img.transpose((1, 2, 0))\n\n   \n    label_name = 'all' if label == 0 else 'hem'\n\n   \n    plt.imshow(img)\n    plt.title(f\"Image: {i+1}, Label: {label_name}\")\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2024-08-14T16:45:12.529729Z","iopub.status.idle":"2024-08-14T16:45:12.53021Z","shell.execute_reply.started":"2024-08-14T16:45:12.530001Z","shell.execute_reply":"2024-08-14T16:45:12.530021Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nfrom torch import nn\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader, random_split, Dataset\n\nclass FractureClassifier(nn.Module):\n    def __init__(self, num_classes=10):\n        super().__init__()\n\n        self.conv1 = nn.Conv2d(in_channels=3, out_channels=8, kernel_size=3)\n        self.conv2 = nn.Conv2d(in_channels=8, out_channels=16, kernel_size=3)\n        self.conv3 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3)\n        self.conv4 = nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3)\n        self.conv5 = nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3)\n        self.conv6 = nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3)\n        \n        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n        self.pool4 = nn.MaxPool2d(kernel_size=2, stride=2)\n        self.pool5 = nn.MaxPool2d(kernel_size=2, stride=2)\n        \n        self.flatten = nn.Flatten()\n        \n        self.linear1 = nn.Linear(32*6*6, 256)\n        self.linear2 = nn.Linear(256, num_classes)\n        \n\n    def forward(self, x):\n        # x - (batch, 3, 256, 256)\n        out = self.conv1(x) # (batch, 8, 254, 254)\n        out = F.relu(out)\n        \n        out = self.conv2(out) # (batch, 16, 252, 252)\n        out = F.relu(out)\n        \n        out = self.pool1(out) # (batch, 16, 126, 126)\n        \n        out = self.conv3(out) # (batch, 32, 124, 124)\n        out = F.relu(out)\n        \n        out = self.pool2(out) # (batch, 32, 62, 62)\n        \n        out = self.conv4(out) # (batch, 32, 60, 60)\n        out = F.relu(out)\n        \n        out = self.pool3(out) # (batch, 32, 30, 30)\n        \n        out = self.conv5(out) # (batch, 32, 28, 28)\n        out = F.relu(out)\n        \n        out = self.pool4(out) # (batch, 32, 14, 14)\n        \n        out = self.conv6(out) # (batch, 32, 12, 12)\n        out = F.relu(out)\n        \n        out = self.pool5(out) # (batch, 32, 6, 6)\n        \n        out = self.flatten(out) # (batch, 32*6*6)\n        \n        out = self.linear1(out)\n        out = F.relu(out)\n\n        out = self.linear2(out)\n        #out = F.softmax(out, dim=-1)\n        return out\n\n\n    def predict(self, X, device='cpu'):\n        X = torch.FloatTensor(np.array(X)).to(device)\n\n        with torch.no_grad():\n          y_pred = self.forward(X)\n\n        return y_pred.cpu().numpy()\n\n\nmodel = FractureClassifier(len(dataset.classes)).to(device)\nmodel","metadata":{"execution":{"iopub.status.busy":"2024-08-14T16:45:12.531747Z","iopub.status.idle":"2024-08-14T16:45:12.532203Z","shell.execute_reply.started":"2024-08-14T16:45:12.532001Z","shell.execute_reply":"2024-08-14T16:45:12.532019Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install -q torchsummary","metadata":{"execution":{"iopub.status.busy":"2024-08-14T16:45:12.534179Z","iopub.status.idle":"2024-08-14T16:45:12.534731Z","shell.execute_reply.started":"2024-08-14T16:45:12.53448Z","shell.execute_reply":"2024-08-14T16:45:12.53451Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torchsummary import summary\n\nsummary(model, input_size=(3, 256, 256))","metadata":{"execution":{"iopub.status.busy":"2024-08-14T16:45:12.536606Z","iopub.status.idle":"2024-08-14T16:45:12.537166Z","shell.execute_reply.started":"2024-08-14T16:45:12.536945Z","shell.execute_reply":"2024-08-14T16:45:12.536966Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss_fn = nn.CrossEntropyLoss()\n\n# Оптимізатор (SGD) для оновлення ваг моделі\noptimizer = torch.optim.Adam(model.parameters(), lr=0.001)","metadata":{"execution":{"iopub.status.busy":"2024-08-14T16:45:12.539868Z","iopub.status.idle":"2024-08-14T16:45:12.540561Z","shell.execute_reply.started":"2024-08-14T16:45:12.540223Z","shell.execute_reply":"2024-08-14T16:45:12.54025Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import time\n\ndef train(model, optimizer, loss_fn, train_dl, val_dl,\n          metrics=None, metrics_name=None, epochs=20, device='cpu', task='regression'):\n    '''\n    Runs training loop for classification problems. Returns Keras-style\n    per-epoch history of loss and accuracy over training and validation data.\n\n    Parameters\n    ----------\n    model : nn.Module\n        Neural network model\n    optimizer : torch.optim.Optimizer\n        Search space optimizer (e.g. Adam)\n    loss_fn :\n        Loss function (e.g. nn.CrossEntropyLoss())\n    train_dl :\n        Iterable dataloader for training data.\n    val_dl :\n        Iterable dataloader for validation data.\n    metrics: list\n        List of sklearn metrics functions to be calculated\n    metrics_name: list\n        List of matrics names\n    epochs : int\n        Number of epochs to run\n    device : string\n        Specifies 'cuda' or 'cpu'\n    task : string\n        type of problem. It can be regression, binary or multiclass\n\n    Returns\n    -------\n    Dictionary\n        Similar to Keras' fit(), the output dictionary contains per-epoch\n        history of training loss, training accuracy, validation loss, and\n        validation accuracy.\n    '''\n\n    print('train() called: model=%s, opt=%s(lr=%f), epochs=%d, device=%s\\n' % \\\n          (type(model).__name__, type(optimizer).__name__,\n           optimizer.param_groups[0]['lr'], epochs, device))\n\n    metrics = metrics if metrics else []\n    metrics_name = metrics_name if metrics_name else [metric.__name__ for metric in metrics]\n\n    history = {} # Collects per-epoch loss and metrics like Keras' fit().\n    history['loss'] = []\n    history['val_loss'] = []\n    for name in metrics_name:\n        history[name] = []\n        history[f'val_{name}'] = []\n\n    start_time_train = time.time()\n\n    for epoch in range(epochs):\n\n        # --- TRAIN AND EVALUATE ON TRAINING SET -----------------------------\n        start_time_epoch = time.time()\n\n        model.train()\n        history_train = {name: 0 for name in ['loss']+metrics_name}\n\n        for batch in train_dl:\n            x    = batch[0].to(device)\n            y    = batch[1].to(device)\n            y_pred = model(x)\n            loss = loss_fn(y_pred, y)\n\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n\n            y_pred = y_pred.detach().cpu().numpy()\n            y = y.detach().cpu().numpy()\n\n\n            history_train['loss'] += loss.item() * x.size(0)\n            for name, func in zip(metrics_name, metrics):\n                try:\n                    history_train[name] += func(y, y_pred) * x.size(0)\n                except:\n                    if task == 'binary': y_pred_ = y_pred.round()\n                    elif task == 'multiclass': y_pred_ = y_pred.argmax(axis=-1)\n                    history_train[name] += func(y, y_pred_) * x.size(0)\n\n        for name in history_train:\n            history_train[name] /= len(train_dl.dataset)\n\n\n        # --- EVALUATE ON VALIDATION SET -------------------------------------\n        model.eval()\n        history_val = {'val_' + name: 0 for name in metrics_name+['loss']}\n\n        with torch.no_grad():\n            for batch in val_dl:\n                x    = batch[0].to(device)\n                y    = batch[1].to(device)\n                y_pred = model(x)\n                loss = loss_fn(y_pred, y)\n\n                y_pred = y_pred.cpu().numpy()\n                y = y.cpu().numpy()\n\n                history_val['val_loss'] += loss.item() * x.size(0)\n                for name, func in zip(metrics_name, metrics):\n                    try:\n                        history_val['val_'+name] += func(y, y_pred) * x.size(0)\n                    except:\n                        if task == 'binary': y_pred_ = y_pred.round()\n                        elif task == 'multiclass': y_pred_ = y_pred.argmax(axis=-1)\n\n                        history_val['val_'+name] += func(y, y_pred_) * x.size(0)\n\n        for name in history_val:\n            history_val[name] /= len(val_dl.dataset)\n\n        # PRINTING RESULTS\n\n        end_time_epoch = time.time()\n\n        for name in history_train:\n            history[name].append(history_train[name])\n            history['val_'+name].append(history_val['val_'+name])\n\n        total_time_epoch = end_time_epoch - start_time_epoch\n\n        print(f'Epoch {epoch+1:4d} {total_time_epoch:4.0f}sec', end='\\t')\n        for name in history_train:\n            print(f'{name}: {history[name][-1]:10.3g}', end='\\t')\n            print(f\"val_{name}: {history['val_'+name][-1]:10.3g}\", end='\\t')\n        print()\n\n    # END OF TRAINING LOOP\n\n    end_time_train       = time.time()\n    total_time_train     = end_time_train - start_time_train\n    print()\n    print('Time total:     %5.2f sec' % (total_time_train))\n\n    return history","metadata":{"execution":{"iopub.status.busy":"2024-08-14T16:45:12.543636Z","iopub.status.idle":"2024-08-14T16:45:12.544341Z","shell.execute_reply.started":"2024-08-14T16:45:12.544011Z","shell.execute_reply":"2024-08-14T16:45:12.544041Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_size = 32  # Вы можете изменить размер батча в зависимости от ваших потребностей\n\ntrain_loader = DataLoader(custom_train_data, batch_size=batch_size, shuffle=True)\ntest_loader = DataLoader(custom_test_data, batch_size=batch_size, shuffle=False)\n","metadata":{"execution":{"iopub.status.busy":"2024-08-14T16:45:12.54711Z","iopub.status.idle":"2024-08-14T16:45:12.547964Z","shell.execute_reply.started":"2024-08-14T16:45:12.547413Z","shell.execute_reply":"2024-08-14T16:45:12.547655Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, roc_auc_score\n\nhistory = train(model, optimizer, loss_fn, train_loader, test_loader,\n                epochs=10,\n                metrics=[accuracy_score],\n                device=device,\n                task='multiclass')","metadata":{"execution":{"iopub.status.busy":"2024-08-14T16:45:12.550065Z","iopub.status.idle":"2024-08-14T16:45:12.550807Z","shell.execute_reply.started":"2024-08-14T16:45:12.550464Z","shell.execute_reply":"2024-08-14T16:45:12.550494Z"},"trusted":true},"execution_count":null,"outputs":[]}]}